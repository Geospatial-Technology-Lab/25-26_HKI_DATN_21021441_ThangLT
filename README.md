# ğŸ”¥ Deep Reinforcement Learning for Wildfire Detection

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Äá»“ Ã¡n tá»‘t nghiá»‡p - Äáº¡i há»c CÃ´ng nghá»‡, Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i**

á»¨ng dá»¥ng cÃ¡c thuáº­t toÃ¡n Deep Reinforcement Learning Ä‘á»ƒ phÃ¡t hiá»‡n Ä‘iá»ƒm nÃ³ng chÃ¡y rá»«ng tá»« dá»¯ liá»‡u áº£nh nhiá»‡t vÃ  dá»¯ liá»‡u thá»i tiáº¿t.

## ğŸ“‹ Má»¥c Lá»¥c

- [Tá»•ng Quan](#-tá»•ng-quan)
- [TÃ­nh NÄƒng Má»›i](#-tÃ­nh-nÄƒng-má»›i-v20)
- [Thuáº­t ToÃ¡n](#-thuáº­t-toÃ¡n-Ä‘Æ°á»£c-triá»ƒn-khai)
- [Cáº¥u TrÃºc Dá»± Ãn](#-cáº¥u-trÃºc-dá»±-Ã¡n)
- [CÃ i Äáº·t](#-cÃ i-Ä‘áº·t)
- [Sá»­ Dá»¥ng](#-sá»­-dá»¥ng)
- [Káº¿t Quáº£](#-káº¿t-quáº£)

---

## ğŸ¯ Tá»•ng Quan

Dá»± Ã¡n nÃ y nghiÃªn cá»©u vÃ  so sÃ¡nh hiá»‡u quáº£ cá»§a cÃ¡c thuáº­t toÃ¡n Deep Reinforcement Learning trong bÃ i toÃ¡n phÃ¡t hiá»‡n chÃ¡y rá»«ng. Agent di chuyá»ƒn trÃªn báº£n Ä‘á»“ nhiá»‡t vÃ  Ä‘Æ°a ra dá»± Ä‘oÃ¡n vá»‹ trÃ­ cÃ³ nguy cÆ¡ chÃ¡y dá»±a trÃªn:

- **Dá»¯ liá»‡u nhiá»‡t Ä‘á»™** (Thermal imagery)
- **Dá»¯ liá»‡u thá»i tiáº¿t**: Ä‘á»™ áº©m, tá»‘c Ä‘á»™ giÃ³, lÆ°á»£ng mÆ°a, nhiá»‡t Ä‘á»™ Ä‘áº¥t
- **Dá»¯ liá»‡u Ä‘á»‹a hÃ¬nh**: DEM, NDMI, Land cover

### Äáº·c Äiá»ƒm Ná»•i Báº­t

- âœ… So sÃ¡nh **10+ thuáº­t toÃ¡n** RL/DRL
- âœ… **CNN-based Observation** (8 channels Ã— 11Ã—11)
- âœ… **ICM Exploration** (Curiosity-driven)
- âœ… **Balanced Reward Structure**
- âœ… Há»— trá»£ **GPU acceleration** (CUDA)
- âœ… **Parallel training** vá»›i multi-agent

---

## ğŸ†• TÃ­nh NÄƒng Má»›i (v2.0)

### 1. CNN-based Observation
- Observation space: `[8, 11, 11]` thay vÃ¬ 1D vector
- 8 channels: thermal, humidity, wind_speed, soil_temp, soil_moisture, rainfall, ndmi, dem
- Há»c Ä‘Æ°á»£c spatial patterns (fire edges, spread direction)

### 2. ICM Exploration (Intrinsic Curiosity Module)
- Curiosity-driven exploration
- Intrinsic rewards dá»±a trÃªn prediction error
- GiÃºp agent khÃ¡m phÃ¡ tá»‘t hÆ¡n trong sparse reward environments

### 3. Balanced Reward Structure
- `false_positive_penalty`: 300 â†’ 50 (giáº£m)
- `false_negative_penalty`: 50 â†’ 100 (tÄƒng)
- ThÃªm `proximity_reward_scale` vÃ  `discovery_bonus`

### 4. Integrated Models
Táº¥t cáº£ 7 DRL algorithms Ä‘á»u cÃ³ phiÃªn báº£n tÃ­ch há»£p vá»›i CNN + ICM:

| Algorithm | Integrated File |
|-----------|-----------------|
| A3C | `a3c/integrated_a3c.py` |
| A2C | `a2c/integrated_a2c.py` |
| PPO | `ppo/integrated_ppo.py` |
| DQN | `dqn/integrated_dqn.py` |
| SAC | `sac/integrated_sac.py` |
| DDPG | `ddpg/integrated_ddpg.py` |
| VPG | `vpg/integrated_vpg.py` |

---

## ğŸ§  Thuáº­t ToÃ¡n ÄÆ°á»£c Triá»ƒn Khai

### Deep Reinforcement Learning
| Thuáº­t toÃ¡n | MÃ´ táº£ | Files |
|------------|-------|-------|
| **A3C** | Asynchronous Advantage Actor-Critic | `a3c/a3c.py`, `a3c/integrated_a3c.py` |
| **PPO** | Proximal Policy Optimization | `ppo/ppo.py`, `ppo/integrated_ppo.py` |
| **DQN** | Deep Q-Network (Dueling Double DQN) | `dqn/dqn.py`, `dqn/integrated_dqn.py` |
| **SAC** | Soft Actor-Critic (Discrete) | `sac/sac.py`, `sac/integrated_sac.py` |
| **DDPG** | Deep Deterministic Policy Gradient | `ddpg/ddpg.py`, `ddpg/integrated_ddpg.py` |
| **VPG** | Vanilla Policy Gradient | `vpg/vpg.py`, `vpg/integrated_vpg.py` |
| **A2C** | Advantage Actor-Critic | `a2c/a2c.py`, `a2c/integrated_a2c.py` |

### Classical RL & Planning
| Thuáº­t toÃ¡n | MÃ´ táº£ | File |
|------------|-------|------|
| **Q-Learning** | Tabular Q-Learning | `q_learning/` |
| **Value Iteration** | Dynamic Programming | `value_iteration/` |
| **Policy Iteration** | Dynamic Programming | `policy_iteration/` |
| **MCTS** | Monte Carlo Tree Search | `mcts/` |

---

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
DRL_Thesis/
â”œâ”€â”€ ğŸ“‚ environment/
â”‚   â”œâ”€â”€ env_src.py              # Original environment
â”‚   â”œâ”€â”€ cnn_env.py              # CNN-based environment (NEW)
â”‚   â””â”€â”€ vec_env.py              # Vectorized environments
â”‚
â”œâ”€â”€ ğŸ“‚ models/
â”‚   â”œâ”€â”€ cnn_network.py          # CNN Actor-Critic networks (NEW)
â”‚   â”œâ”€â”€ icm.py                  # Intrinsic Curiosity Module (NEW)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ ğŸ“‚ a3c/
â”‚   â”œâ”€â”€ a3c.py                  # Original A3C
â”‚   â”œâ”€â”€ a3c_main.py             # Training script
â”‚   â””â”€â”€ integrated_a3c.py       # CNN + ICM integrated (NEW)
â”‚
â”œâ”€â”€ ğŸ“‚ [other algorithms]/      # Similar structure
â”‚
â”œâ”€â”€ ğŸ“‚ examples/
â”‚   â””â”€â”€ train_integrated.py     # Example training script
â”‚
â”œâ”€â”€ train_integrated_main.py    # Unified training script (NEW)
â”œâ”€â”€ evaluate_integrated.py      # Quick evaluation (NEW)
â”œâ”€â”€ evaluate_integrated_full.py # Full patch evaluation (NEW)
â”œâ”€â”€ config.py                   # Configuration
â””â”€â”€ README.md
```

---

## ğŸ›  CÃ i Äáº·t

### YÃªu Cáº§u

- Python 3.8+
- CUDA 11.0+ (optional, for GPU)
- Git LFS (for large data files)

### CÃ i Äáº·t

```bash
# Install Git LFS first
git lfs install

# Clone repository
git clone https://github.com/Geospatial-Technology-Lab/25-26_HKI_DATN_21021441_ThangLT.git
cd 25-26_HKI_DATN_21021441_ThangLT

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Install dependencies
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install numpy pandas matplotlib scipy rasterio tqdm gym scikit-learn
```

---

## ğŸš€ Sá»­ Dá»¥ng

### 1. Training vá»›i Integrated Models (KhuyÃªn dÃ¹ng)

```bash
# Train A3C vá»›i CNN + ICM
python train_integrated_main.py --algorithm a3c --episodes 500 --device cuda

# Train PPO
python train_integrated_main.py --algorithm ppo --episodes 500 --device cuda

# Train táº¥t cáº£ algorithms
for algo in a3c a2c ppo dqn sac ddpg vpg; do
    python train_integrated_main.py --algorithm $algo --episodes 500 --device cuda
done

# Options
python train_integrated_main.py --help
  --algorithm    # a3c, a2c, ppo, dqn, sac, ddpg, vpg
  --episodes     # Number of training episodes (default: 500)
  --agents       # Number of parallel agents (default: 4)
  --device       # cuda or cpu
  --no_icm       # Disable ICM exploration
  --use_synthetic # Use synthetic data for testing
```

### 2. Evaluation

```bash
# Quick evaluation (sample region)
python evaluate_integrated.py --algorithm a3c --device cuda

# Full evaluation (all patches - like a3c_main.py)
python evaluate_integrated_full.py --algorithm a3c --device cuda

# Limit patches for faster testing
python evaluate_integrated_full.py --algorithm a3c --device cuda --max_patches 100

# Compare all algorithms
python evaluate_integrated_full.py --algorithm all --device cuda --max_patches 100
```

### 3. Training vá»›i Original Models

```bash
# A3C original
cd a3c && python a3c_main.py

# DQN original  
cd dqn && python dqn_main.py
```

---

## ğŸ“Š Dá»¯ Liá»‡u

### Cáº¥u TrÃºc Dá»¯ Liá»‡u

```
data/
â””â”€â”€ thermal_raster_final.tif    # áº¢nh nhiá»‡t (15132 Ã— 6442)

database/
â”œâ”€â”€ aligned_landcover.tif       # Land cover
â”œâ”€â”€ aligned_humidity.tif        # Äá»™ áº©m
â”œâ”€â”€ aligned_wind_speed.tif      # Tá»‘c Ä‘á»™ giÃ³
â”œâ”€â”€ aligned_rainfall.tif        # LÆ°á»£ng mÆ°a
â”œâ”€â”€ aligned_soil_temp.tif       # Nhiá»‡t Ä‘á»™ Ä‘áº¥t
â”œâ”€â”€ aligned_soil_moisture.tif   # Äá»™ áº©m Ä‘áº¥t
â”œâ”€â”€ aligned_dem.tif             # Digital Elevation Model
â””â”€â”€ aligned_ndmi.tif            # NDMI index
```

---

## ğŸ“ˆ Káº¿t Quáº£

Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c lÆ°u trong `{algorithm}_results/`:

- `training_results.json` - Training history
- `full_evaluation_results.csv` - Per-patch metrics
- `full_evaluation_summary.json` - Summary metrics
- `evaluation_plot.png` - Visualization

### Metrics
| Metric | MÃ´ táº£ |
|--------|-------|
| AUC-ROC | Area Under ROC Curve |
| PR-AUC | Area Under Precision-Recall Curve |
| F1 | Harmonic mean of Precision & Recall |
| Precision | TP / (TP + FP) |
| Recall | TP / (TP + FN) |

---

## ğŸ”§ TÃ­nh NÄƒng Tá»‘i Æ¯u

### CNN Environment (`cnn_env.py`)
- Observation: `[8, 11, 11]` spatial features
- Integrated balanced rewards
- Proximity and discovery bonuses

### ICM Module (`models/icm.py`)
- `CNNIntrinsicCuriosityModule` for CNN observations
- Forward/Inverse model for curiosity
- Configurable intrinsic reward scale

### Training Optimizations
- Multi-agent parallel training
- GPU acceleration (batch size 1024)
- Running reward averaging
- Periodic model checkpointing

---

## ğŸ‘¤ TÃ¡c Giáº£

**LÃª ToÃ n Tháº¯ng**
- MÃ£ sinh viÃªn: 21021441
- TrÆ°á»ng: Äáº¡i há»c CÃ´ng nghá»‡, Äáº¡i há»c Quá»‘c gia HÃ  Ná»™i
- Email: toanthangvietduc@gmail.com

---

## ğŸ“„ License

MIT License - Xem file [LICENSE](LICENSE) Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

---

## ğŸ™ Acknowledgments

- Geospatial Technology Lab - VNU
- PyTorch Team
- OpenAI Gym